{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9228f82dc464ee09f83b311cf275135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_visible, n_hidden, n_cond=0, conditional=False):\n",
    "        super(RBM, self).__init__()\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_cond = n_cond\n",
    "        self.conditional = conditional\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(n_visible, n_hidden).to(device) * 0.01)\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hidden).to(device))\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_visible).to(device))\n",
    "\n",
    "        if self.conditional:\n",
    "            self.U = nn.Parameter(torch.randn(n_cond, n_hidden).to(device) * 0.01)\n",
    "\n",
    "    def sample_h(self, v, c=None):\n",
    "        if self.conditional:\n",
    "            activation = torch.matmul(v, self.W) + self.h_bias + torch.matmul(c, self.U)\n",
    "        else:\n",
    "            activation = torch.matmul(v, self.W) + self.h_bias\n",
    "        p_h = torch.sigmoid(activation)\n",
    "        return p_h, torch.bernoulli(p_h)\n",
    "\n",
    "    def sample_v(self, h):\n",
    "        activation = torch.matmul(h, self.W.t()) + self.v_bias\n",
    "        p_v = torch.sigmoid(activation)\n",
    "        return p_v, torch.bernoulli(p_v)\n",
    "\n",
    "    def contrastive_divergence(self, v0, c0=None, k=1):\n",
    "        p_h0, h0 = self.sample_h(v0, c0) if self.conditional else self.sample_h(v0)\n",
    "        v_k = v0\n",
    "        for _ in range(k):\n",
    "            p_h, h_k = self.sample_h(v_k, c0) if self.conditional else self.sample_h(v_k)\n",
    "            p_v, v_k = self.sample_v(h_k)\n",
    "        p_hk, h_k = self.sample_h(v_k, c0) if self.conditional else self.sample_h(v_k)\n",
    "\n",
    "        positive_grad = torch.matmul(v0.t(), p_h0)\n",
    "        negative_grad = torch.matmul(v_k.t(), p_hk)\n",
    "\n",
    "        if self.conditional:\n",
    "            self.U.grad = -(torch.matmul(c0.t(), (p_h0 - p_hk))) / v0.size(0)\n",
    "\n",
    "        self.W.grad = -(positive_grad - negative_grad) / v0.size(0)\n",
    "        self.v_bias.grad = -(torch.sum(v0 - v_k, dim=0)) / v0.size(0)\n",
    "        self.h_bias.grad = -(torch.sum(p_h0 - p_hk, dim=0)) / v0.size(0)\n",
    "\n",
    "    def generate(self, c=None, n_samples=10, gibbs_steps=1000):\n",
    "        samples = []\n",
    "        v = torch.bernoulli(torch.rand(n_samples, self.n_visible).to(device))\n",
    "        for _ in range(gibbs_steps):\n",
    "            p_h, h = self.sample_h(v, c) if self.conditional else self.sample_h(v)\n",
    "            p_v, v = self.sample_v(h)\n",
    "        samples.append(v.detach().cpu())\n",
    "        return torch.cat(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_tabular_data(file_path, target_col):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.drop(target_col, axis=1).values\n",
    "    y = df[target_col].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_encoded = encoder.fit_transform(y)\n",
    "    return torch.tensor(X, dtype=torch.float32).to(device), torch.tensor(y_encoded, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distributions(real_data, synthetic_data):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(min(real_data.shape[1], 5)):\n",
    "        sns.kdeplot(real_data[:, i], color=\"blue\", label=\"Real\" if i == 0 else \"\")\n",
    "        sns.kdeplot(synthetic_data[:, i], color=\"red\", label=\"Synthetic\" if i == 0 else \"\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Distribution comparison between Real and Synthetic data\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(dataset='mnist', custom_path=None, target_col=None, conditional=False, epochs=5):\n",
    "    if dataset == 'mnist':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "        data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        data_loader = torch.utils.data.DataLoader(data, batch_size=64, shuffle=True)\n",
    "        n_visible, n_hidden, n_cond = 784, 256, 10\n",
    "    else:\n",
    "        X, y = load_and_prepare_tabular_data(custom_path, target_col)\n",
    "        n_visible, n_hidden, n_cond = X.shape[1], 128, y.shape[1]\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    rbm = RBM(n_visible, n_hidden, n_cond, conditional=conditional).to(device)\n",
    "    optimizer = torch.optim.SGD(rbm.parameters(), lr=0.05)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in data_loader:\n",
    "            if dataset == 'mnist':\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                c = F.one_hot(labels, num_classes=10).float() if conditional else None\n",
    "                v0 = images\n",
    "            else:\n",
    "                v0, c = batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            rbm.contrastive_divergence(v0, c, k=1)\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}/{epochs} completed.')\n",
    "\n",
    "    print(\"Training completed. Generating synthetic data...\")\n",
    "\n",
    "    c_gen = torch.eye(n_cond).to(device) if conditional else None\n",
    "    synthetic_data = rbm.generate(c_gen, n_samples=1000, gibbs_steps=500).cpu().numpy()\n",
    "\n",
    "    if dataset == 'mnist':\n",
    "        fig, axes = plt.subplots(1, 10, figsize=(15, 2))\n",
    "        synthetic_data_reshaped = synthetic_data.reshape(-1, 28, 28)\n",
    "        for i in range(10):\n",
    "            axes[i].imshow(synthetic_data_reshaped[i], cmap='gray')\n",
    "            axes[i].axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        visualize_distributions(X.cpu().numpy(), synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:41<00:00, 238821.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 98853.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:09<00:00, 175393.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Epoch 1/5 completed.\n",
      "Epoch 2/5 completed.\n",
      "Epoch 3/5 completed.\n",
      "Epoch 4/5 completed.\n",
      "Epoch 5/5 completed.\n",
      "Training completed. Generating synthetic data...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1000) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m, in \u001b[0;36mtrain_pipeline\u001b[1;34m(dataset, custom_path, target_col, conditional, epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed. Generating synthetic data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m c_gen \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(n_cond)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mif\u001b[39;00m conditional \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m \u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgibbs_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     37\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m, in \u001b[0;36mRBM.generate\u001b[1;34m(self, c, n_samples, gibbs_steps)\u001b[0m\n\u001b[0;32m     49\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbernoulli(torch\u001b[38;5;241m.\u001b[39mrand(n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_visible)\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(gibbs_steps):\n\u001b[1;32m---> 51\u001b[0m     p_h, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditional \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_h(v)\n\u001b[0;32m     52\u001b[0m     p_v, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_v(h)\n\u001b[0;32m     53\u001b[0m samples\u001b[38;5;241m.\u001b[39mappend(v\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m, in \u001b[0;36mRBM.sample_h\u001b[1;34m(self, v, c)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_h\u001b[39m(\u001b[38;5;28mself\u001b[39m, v, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditional:\n\u001b[1;32m---> 18\u001b[0m         activation \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh_bias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m         activation \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_bias\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1000) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "train_pipeline(dataset='mnist', conditional=True, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
